### 功能需求
1.日志消息有多种级别
2.日志消息可能有多个目的地
3.日志消息的格式可配置
4.可是设置运行时过滤器
5.方便使用，比如：<<

特定的日志消息格式
比如：日期(年月日)+时间(时分秒)+微秒+线程id+日志级别+日志内容+源文件+行号

可以临时调整日志输出级别
日志文件可以滚动，按大小、按时间进行滚动
特定的日志名格式

### 性能需求
只有日志库足够高效，才敢在代码中输出足够多的诊断信息

1.日志库应该能瞬间写满硬盘带宽（110MB/s）假设日志长度为110字节，则一秒要写100万条日志
2.能应对一个进程产生大量日志数据的场景，例如1GB/min
3.不阻塞正常的执行流程
4.多线程程序中，线程安全且不造成争用

### 测试
单线程写入
多线程并发写入

### 使用方式
LOG_INFO << "AAA";

LOG_INFO是一个宏，展开后为：

Logger(__FILE__, __LINE__).stream() << "AAA";

构造了一个匿名对象Logger，在这个对象构造的时候其实已经写入了文件名和行号。

匿名对象调用.stream()函数拿到一个LogStream对象，由这个LogStream对象重载<<将“AAA”写入LogStream的数据成员FixBuffer对象的data_缓冲区内。

匿名对象在这条语句执行完毕以后会被销毁，因此会调用~Logger()函数将日志消息输出至目的地（标准输出或者磁盘的日志文件）；

日志的流程：
Logger——Impl——LogStream——operator<<——LogStream的FixBuffer内——g_output——g_flush

### 问题
为什么不用iostream来输出而是另写一个logstream?
iostream 不适合带格式的数据  没办法在多线程程序中保证一行的完整性
要么自己封装  要么使用c的那一套

### 设计亮点
实现了基于多缓冲技术的线程安全高性能异步日志库，写入速度为135万条消息/s
tricks:
1.在编译期完成一些任务加快速度
2.日志时间，在一秒内重复使用，减少不必要的重新组装时间; tid重复使用
3.多缓冲区
好处：
异步写入，不必等待日志写操作完成，避免阻塞业务逻辑
避免每条日志都触发后台线程，降低开销
不足：
实现上用了一个全局锁，并发量太多时性能会下降。一个解决思路是：不同线程hash到不同桶中，减少竞争
无锁数据结构呢？
